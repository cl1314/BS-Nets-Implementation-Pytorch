{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Salinas : msd modified.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ucalyptus/BS-Nets-Implementation-Pytorch/blob/dual-attention/Salinas_msd_modified.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i-WGRlA3KyxB",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras import regularizers\n",
        "from keras.layers import Conv2D, Conv3D, Flatten, Dense, Reshape, BatchNormalization, ReLU, PReLU, MaxPool3D, Conv3DTranspose\n",
        "from keras.layers import Dropout, Input, GlobalAveragePooling2D, multiply, add, Activation, Permute, merge\n",
        "from keras.models import Model, Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "from keras.layers import Layer\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, cohen_kappa_score\n",
        "\n",
        "from operator import truediv\n",
        "\n",
        "# from plotly.offline import init_notebook_mode\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io as sio\n",
        "import os\n",
        "# import spectral\n",
        "\n",
        "# init_notebook_mode(connected=True)\n",
        "%matplotlib inline\n",
        "# %tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D7_l6NRBKyxH",
        "outputId": "e6dc90f6-44d7-4ef0-f6d6-1c6fae94270f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!pip install -U spectral\n",
        "if not (os.path.isfile('/content/Salinas_corrected.mat')):\n",
        "  !wget https://github.com/gokriznastic/HybridSN/raw/master/data/Salinas_corrected.mat\n",
        "if not (os.path.isfile('/content/Salinas_gt.mat')):\n",
        "  !wget https://github.com/gokriznastic/HybridSN/raw/master/data/Salinas_gt.mat"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: spectral in /usr/local/lib/python3.6/dist-packages (0.20)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from spectral) (1.17.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ayKszFCcKyxJ",
        "colab": {}
      },
      "source": [
        "def loadData():\n",
        "    \n",
        "    data = sio.loadmat('Salinas_corrected.mat')['salinas_corrected']\n",
        "    labels = sio.loadmat('Salinas_gt.mat')['salinas_gt']\n",
        "    \n",
        "    return data, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Zyw923t1KyxM",
        "colab": {}
      },
      "source": [
        "def padWithZeros(X, margin=2):\n",
        "    newX = np.zeros((X.shape[0] + 2 * margin, X.shape[1] + 2* margin, X.shape[2]))\n",
        "    x_offset = margin\n",
        "    y_offset = margin\n",
        "    newX[x_offset:X.shape[0] + x_offset, y_offset:X.shape[1] + y_offset, :] = X\n",
        "    return newX"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "j-pUBs9hKyxO",
        "colab": {}
      },
      "source": [
        "def createImageCubes(X, y, windowSize=5, removeZeroLabels = True):\n",
        "    margin = int((windowSize - 1) / 2)\n",
        "    zeroPaddedX = padWithZeros(X, margin=margin)\n",
        "    # split patches\n",
        "    patchesData = np.zeros((X.shape[0] * X.shape[1], windowSize, windowSize, X.shape[2]))\n",
        "    patchesLabels = np.zeros((X.shape[0] * X.shape[1]))\n",
        "    patchIndex = 0\n",
        "    for r in range(margin, zeroPaddedX.shape[0] - margin):\n",
        "        for c in range(margin, zeroPaddedX.shape[1] - margin):\n",
        "            patch = zeroPaddedX[r - margin:r + margin + 1, c - margin:c + margin + 1]   \n",
        "            patchesData[patchIndex, :, :, :] = patch\n",
        "            patchesLabels[patchIndex] = y[r-margin, c-margin]\n",
        "            patchIndex = patchIndex + 1\n",
        "    if removeZeroLabels:\n",
        "        patchesData = patchesData[patchesLabels>0,:,:,:]\n",
        "        patchesLabels = patchesLabels[patchesLabels>0]\n",
        "        patchesLabels -= 1\n",
        "    return patchesData, patchesLabels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0qgTzXVKKyxQ",
        "colab": {}
      },
      "source": [
        "X, y = loadData()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8Fdu_Qsz7MZN",
        "outputId": "c529ec20-48fb-4bdb-f85f-cdcc30ad825e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(512, 217, 204)\n",
            "(512, 217)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wPbCGwgrKyxT",
        "outputId": "e87c6931-9da6-4a80-eeea-ef0dfef95814",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X, y = createImageCubes(X, y, 5)\n",
        "\n",
        "X.shape, y.shape"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((54129, 5, 5, 204), (54129,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weoj9D0z4wzT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"X = X.reshape(-1,5,5,204)\n",
        "ENTROPY = np.zeros([54129,204])\n",
        "for b in range(0,54129):  \n",
        "  band_subset = X[b,:,:,:]\n",
        "  n_row,n_column,n_band= band_subset.shape\n",
        "  N = n_row * n_column\n",
        "  hist = []\n",
        "  for i in range(n_band):\n",
        "    hist_, _ = np.histogram(band_subset[:, :, i], 256)\n",
        "    hist.append(hist_ / N)\n",
        "    band_i = hist[i].reshape(-1)/np.sum(hist[i])\n",
        "    entr_i = entropy(band_i)\n",
        "    ENTROPY[b][i] += entr_i  ## the entropy of one band of one batch\n",
        "  hist = np.asarray(hist)\n",
        "  hist[np.nonzero(hist <= 0)] = 1e-1\n",
        "\n",
        "fig = plt.figure(figsize=(40,10))\n",
        "ax1 = fig.add_subplot(121)\n",
        "ax1.plot(np.average(ENTROPY,axis =0))\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CmInivJsKyxW"
      },
      "source": [
        "# Model and Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uMnbZ0zj5hdJ",
        "colab": {}
      },
      "source": [
        "def BAM():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(filters=64,\n",
        "                     input_shape=(5, 5, 204),\n",
        "                     kernel_size=(3,3),\n",
        "                     strides=1,\n",
        "                     padding='valid', name=\"Conv1\"))\n",
        "    model.add(ReLU(name=\"ReLU1\"))\n",
        "    model.add(GlobalAveragePooling2D(data_format=\"channels_first\"))\n",
        "    \n",
        "    model.add(Dense(128))\n",
        "    model.add(ReLU(name=\"ReLU2\"))\n",
        "    model.add(Dense(204, activation=\"sigmoid\"))\n",
        "  \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dvQBnOxVKyxZ",
        "colab": {}
      },
      "source": [
        "def DCAE(weight_decay=0.0005):\n",
        "    model = Sequential()\n",
        "    model.add(Conv3D(filters=24,\n",
        "                     input_shape=(204, 5, 5, 1),\n",
        "                     kernel_size=(24, 3, 3),\n",
        "                     strides=(1, 1, 1),\n",
        "                     kernel_regularizer=regularizers.l2(l=weight_decay),\n",
        "                     padding='valid', name=\"Conv1\"))  \n",
        "    model.add(BatchNormalization(name=\"BN1\"))\n",
        "    model.add(PReLU(name=\"PReLU1\"))\n",
        "\n",
        "    model.add(Conv3D(filters=48,\n",
        "                     kernel_size=(24, 3, 3),  \n",
        "                     strides=(1, 1, 1),\n",
        "                     kernel_regularizer=regularizers.l2(l=weight_decay),\n",
        "                     padding='valid', name=\"Conv2\"))  \n",
        "    model.add(BatchNormalization(name=\"BN2\"))\n",
        "    model.add(PReLU(name=\"PReLU2\"))\n",
        "\n",
        "    model.add(MaxPool3D(pool_size=(18, 1, 1),\n",
        "                        strides=(18, 1, 1), name=\"Pool1\"))\n",
        "\n",
        "    model.add(Conv3DTranspose(filters=24,\n",
        "                              kernel_size=(32, 3, 3), #(9,3,3),\n",
        "                              kernel_regularizer=regularizers.l2(\n",
        "                                  l=weight_decay),\n",
        "                              strides=(22, 1, 1), name=\"Deconv1\", padding='valid'))\n",
        "    model.add(BatchNormalization(name=\"BN3\"))\n",
        "    model.add(PReLU(name=\"PReLU3\"))\n",
        "    model.add(Conv3DTranspose(filters=1,\n",
        "                              kernel_size=(19, 3, 3),\n",
        "                              kernel_regularizer=regularizers.l2(\n",
        "                                  l=weight_decay),\n",
        "                              strides=(1, 1, 1), name=\"Deconv2\", padding='valid'))\n",
        "    model.add(BatchNormalization(name=\"BN4\"))\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fPtnuhhpDAC8",
        "colab": {}
      },
      "source": [
        "def Ensemble():\n",
        "    input_layer = Input((5, 5, 204))\n",
        "    band_activations = BAM()(input_layer)\n",
        "    # band_activations = Reshape((200, 1, 1))(band_activations)\n",
        "    \n",
        "    bam_output = multiply([band_activations, input_layer])\n",
        "    \n",
        "    bam_output = Reshape((204, 5, 5, 1))(bam_output)\n",
        "    \n",
        "    output = DCAE()(bam_output)\n",
        "    \n",
        "    \n",
        "    return Model(inputs=input_layer, outputs=output)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CdiDxfoAKyxb",
        "outputId": "6d10fd32-3f80-4506-9c05-6cd9b7533f64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "# model = DCAE(weight_decay=0.0005)\n",
        "model = Ensemble()\n",
        "model.summary()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_10\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_11 (InputLayer)           (None, 5, 5, 204)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_20 (Sequential)      (None, 204)          144396      input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "multiply_11 (Multiply)          (None, 5, 5, 204)    0           sequential_20[1][0]              \n",
            "                                                                 input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "reshape_10 (Reshape)            (None, 204, 5, 5, 1) 0           multiply_11[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "sequential_21 (Sequential)      (None, 204, 5, 5, 1) 677237      reshape_10[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 821,633\n",
            "Trainable params: 821,439\n",
            "Non-trainable params: 194\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9_CzHPG7Tvo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def MeanSpectralDivergence(band_subset):\n",
        "\n",
        "  n_row, n_column, n_band = band_subset.shape\n",
        "  N = n_row * n_column\n",
        "  hist = []\n",
        "  for i in range(n_band):\n",
        "    hist_, _ = np.histogram(band_subset[:, :, i], 256)\n",
        "    hist.append(hist_ / N)\n",
        "  hist = np.asarray(hist)\n",
        "  hist[np.nonzero(hist <= 0)] = 1e-20\n",
        "    # entropy_lst = entropy(hist.transpose())\n",
        "  info_div = 0\n",
        "    # band_subset[np.nonzero(band_subset <= 0)] = 1e-20\n",
        "  for b_i in range(n_band):\n",
        "    for b_j in range(n_band):\n",
        "      band_i = hist[b_i].reshape(-1)/np.sum(hist[b_i])\n",
        "      band_j = hist[b_j].reshape(-1)/np.sum(hist[b_j])\n",
        "      entr_ij = entropy(band_i, band_j)\n",
        "      entr_ji = entropy(band_j, band_i)\n",
        "      entr_sum = entr_ij + entr_ji\n",
        "      info_div += entr_sum\n",
        "  msd = info_div * 2 / (n_band * (n_band - 1))\n",
        "  return msd\n",
        "def MSD2(x_predict,topbandindices):\n",
        "  ##create band_subset\n",
        "  x_predict = x_predict.reshape(54129,204,5,5)\n",
        "  #print(x_predict.shape)                                        ## 54129,204,5,5\n",
        "  band_subset_list = []\n",
        "  for i in range(0,len(topbandindices)):\n",
        "    band_subset_list.append(x_predict[:,i,:,:])     \n",
        "  band_subset = np.array(band_subset_list)    \n",
        "  #print(band_subset.shape)                                      ## band_subset.shape = ## 15,54129,5,5\n",
        "  band_subset = np.stack(band_subset,axis = 1)     \n",
        "  #print(band_subset.shape)                                      ## required shape is [54129,15,5,5] \n",
        "  band_subset = band_subset.reshape(54129,5,5,-1)\n",
        "  #print(band_subset.shape)                \n",
        "  xx = []\n",
        "  for k in range(0,54129):\n",
        "    xx.append(MeanSpectralDivergence(band_subset[k,:,:,:]))   \n",
        "                                                                ## then reshape to [54129,5,5,15] \n",
        "  print(np.average(np.array(xx)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-Lt3ejW8OkA3",
        "colab": {}
      },
      "source": [
        "ENTROPY = np.zeros(204)\n",
        "from scipy.stats import entropy\n",
        "import skimage.measure\n",
        "def topkbands(x_predict, topk):\n",
        "  for i in range(0,len(ENTROPY)):\n",
        "    ENTROPY[i]+=entropy(np.unique(x_predict[:,i,:,:],return_counts=True)[1],base=2)\n",
        "  \n",
        "  \n",
        "  return ENTROPY.argsort()[-topk:][::-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2x0UcifSKyxj",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import Callback\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import math\n",
        "\n",
        "class MyLogger(Callback):\n",
        "    def on_train_end(self,logs=None):\n",
        "      x_predict = model.predict(X)\n",
        "      bandlist = topkbands(x_predict, 15)\n",
        "      with open('BANDLIST.txt', 'w') as filehandle:\n",
        "        for banditem in bandlist:\n",
        "          filehandle.write('%s\\n' % banditem)  ## Manually download BANDLIST.txt from colab.\n",
        "      MSD2(x_predict, bandlist)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bJYuFFA6Kyxl",
        "outputId": "6366203d-210a-43c9-d549-0ee088abd853",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.compile(loss=keras.losses.mse, optimizer=keras.optimizers.Adam(lr=0.1))\n",
        "\n",
        "n_epoch = 50\n",
        "\n",
        "model.fit(X, X.reshape(-1, 204, 5, 5, 1), epochs=n_epoch, shuffle=True, verbose=1, batch_size=256, callbacks=[MyLogger()])"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "54129/54129 [==============================] - 23s 418us/step - loss: 122740.2458\n",
            "Epoch 2/50\n",
            "54129/54129 [==============================] - 20s 377us/step - loss: 102999.3972\n",
            "Epoch 3/50\n",
            "54129/54129 [==============================] - 20s 375us/step - loss: 86063.8991\n",
            "Epoch 4/50\n",
            "54129/54129 [==============================] - 20s 373us/step - loss: 71534.2658\n",
            "Epoch 5/50\n",
            "54129/54129 [==============================] - 20s 376us/step - loss: 58786.4947\n",
            "Epoch 6/50\n",
            "54129/54129 [==============================] - 20s 377us/step - loss: 47964.4224\n",
            "Epoch 7/50\n",
            "54129/54129 [==============================] - 20s 372us/step - loss: 38604.7324\n",
            "Epoch 8/50\n",
            "54129/54129 [==============================] - 20s 375us/step - loss: 30734.5823\n",
            "Epoch 9/50\n",
            "54129/54129 [==============================] - 20s 373us/step - loss: 24104.8680\n",
            "Epoch 10/50\n",
            "54129/54129 [==============================] - 20s 371us/step - loss: 18651.3598\n",
            "Epoch 11/50\n",
            "54129/54129 [==============================] - 20s 373us/step - loss: 14331.9969\n",
            "Epoch 12/50\n",
            "54129/54129 [==============================] - 20s 372us/step - loss: 10793.4833\n",
            "Epoch 13/50\n",
            "54129/54129 [==============================] - 20s 372us/step - loss: 8065.3419\n",
            "Epoch 14/50\n",
            "54129/54129 [==============================] - 20s 372us/step - loss: 5894.9139\n",
            "Epoch 15/50\n",
            "54129/54129 [==============================] - 20s 374us/step - loss: 4632.5786\n",
            "Epoch 16/50\n",
            "54129/54129 [==============================] - 20s 371us/step - loss: 3372.3876\n",
            "Epoch 17/50\n",
            "54129/54129 [==============================] - 20s 372us/step - loss: 2777.1755\n",
            "Epoch 18/50\n",
            "54129/54129 [==============================] - 20s 371us/step - loss: 2273.1850\n",
            "Epoch 19/50\n",
            "54129/54129 [==============================] - 20s 367us/step - loss: 2021.2788\n",
            "Epoch 20/50\n",
            "54129/54129 [==============================] - 20s 369us/step - loss: 1775.9639\n",
            "Epoch 21/50\n",
            "54129/54129 [==============================] - 20s 370us/step - loss: 1681.1407\n",
            "Epoch 22/50\n",
            "54129/54129 [==============================] - 20s 368us/step - loss: 1577.6792\n",
            "Epoch 23/50\n",
            "54129/54129 [==============================] - 20s 369us/step - loss: 1514.3029\n",
            "Epoch 24/50\n",
            "54129/54129 [==============================] - 20s 369us/step - loss: 1452.8098\n",
            "Epoch 25/50\n",
            "54129/54129 [==============================] - 20s 367us/step - loss: 1630.2208\n",
            "Epoch 26/50\n",
            "54129/54129 [==============================] - 20s 367us/step - loss: 1491.5423\n",
            "Epoch 27/50\n",
            "54129/54129 [==============================] - 20s 367us/step - loss: 1422.7331\n",
            "Epoch 28/50\n",
            "54129/54129 [==============================] - 20s 366us/step - loss: 1382.4919\n",
            "Epoch 29/50\n",
            "54129/54129 [==============================] - 20s 367us/step - loss: 1480.7108\n",
            "Epoch 30/50\n",
            "54129/54129 [==============================] - 20s 369us/step - loss: 1514.9447\n",
            "Epoch 31/50\n",
            "54129/54129 [==============================] - 20s 367us/step - loss: 1617.7999\n",
            "Epoch 32/50\n",
            "54129/54129 [==============================] - 20s 368us/step - loss: 1819.6808\n",
            "Epoch 33/50\n",
            "54129/54129 [==============================] - 20s 367us/step - loss: 1781.1142\n",
            "Epoch 34/50\n",
            "54129/54129 [==============================] - 20s 366us/step - loss: 1449.6264\n",
            "Epoch 35/50\n",
            "54129/54129 [==============================] - 20s 365us/step - loss: 1512.1868\n",
            "Epoch 36/50\n",
            "54129/54129 [==============================] - 20s 366us/step - loss: 1717.1537\n",
            "Epoch 37/50\n",
            "54129/54129 [==============================] - 20s 368us/step - loss: 1465.9838\n",
            "Epoch 38/50\n",
            "54129/54129 [==============================] - 20s 367us/step - loss: 1498.4714\n",
            "Epoch 39/50\n",
            "54129/54129 [==============================] - 20s 366us/step - loss: 1559.6873\n",
            "Epoch 40/50\n",
            "54129/54129 [==============================] - 20s 366us/step - loss: 1644.3661\n",
            "Epoch 41/50\n",
            "54129/54129 [==============================] - 20s 368us/step - loss: 1577.8478\n",
            "Epoch 42/50\n",
            "54129/54129 [==============================] - 20s 366us/step - loss: 1478.2264\n",
            "Epoch 43/50\n",
            "54129/54129 [==============================] - 20s 364us/step - loss: 1528.2301\n",
            "Epoch 44/50\n",
            "54129/54129 [==============================] - 20s 366us/step - loss: 1463.4811\n",
            "Epoch 45/50\n",
            "54129/54129 [==============================] - 20s 365us/step - loss: 1375.1728\n",
            "Epoch 46/50\n",
            "54129/54129 [==============================] - 20s 365us/step - loss: 1421.6287\n",
            "Epoch 47/50\n",
            "54129/54129 [==============================] - 20s 366us/step - loss: 1675.4929\n",
            "Epoch 48/50\n",
            "54129/54129 [==============================] - 20s 365us/step - loss: 1535.5529\n",
            "Epoch 49/50\n",
            "54129/54129 [==============================] - 20s 366us/step - loss: 1462.8044\n",
            "Epoch 50/50\n",
            "54129/54129 [==============================] - 20s 366us/step - loss: 1549.2067\n",
            "128.79096099328999\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0e22b906d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vl_fSjufjcGY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}